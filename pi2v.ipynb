{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f52cbb85",
   "metadata": {},
   "source": [
    "# Loading wikipedia bios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4c5e25",
   "metadata": {},
   "source": [
    "## loading raw identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a2eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "df = pd.read_csv('FinalDataFrame5.csv')\n",
    "df.identities = df.identities.apply(literal_eval)\n",
    "bios = list(df['identities'])\n",
    "\n",
    "bios[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeb456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rest is similar to twitter bios approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a048cc",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Loading twitter bios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85b010d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## load all raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a19f38e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/user/smadani/navid/data/pis2020.pkl', 'rb') as f:\n",
    "    bios = pickle.load(f)\n",
    "    \n",
    "bios[100:110]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc70cc9",
   "metadata": {},
   "source": [
    "# PI frequency and top PIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e3926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "cntr = Counter()\n",
    "\n",
    "for bio in bios:\n",
    "    cntr.update(bio)\n",
    "\n",
    "print(len(bios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0aa7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "freqs = list(cntr.values())\n",
    "print(f\"percentile freq: {np.percentile(freqs, 90)} mean freq: {np.mean(freqs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48510dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_pis = {k:v for k,v in cntr.items() if v > 5}\n",
    "len(most_frequent_pis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b0dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'pi': list(most_frequent_pis.keys()), 'cnt': list(most_frequent_pis.values())})\n",
    "df = df.sort_values(by=['cnt'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5a2723",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('wiki_most_frequent_pis.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7c6460",
   "metadata": {},
   "source": [
    "### most frequent neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aeea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "neighbor_cnt = {}\n",
    "\n",
    "for bio in tqdm(bios):\n",
    "    for pi in bio:\n",
    "        if pi in most_frequent_pis:\n",
    "            if pi not in neighbor_cnt:\n",
    "                neighbor_cnt[pi] = Counter()\n",
    "                \n",
    "            rest = [b for b in bio if b!=pi and b in most_frequent_pis]\n",
    "            neighbor_cnt[pi].update(rest)\n",
    "\n",
    "print(len(neighbor_cnt))            \n",
    "\n",
    "#post processing and pruning empty adjacencies\n",
    "\n",
    "for pi, adj in neighbor_cnt.copy().items():\n",
    "    if len(adj) < 2:\n",
    "        neighbor_cnt.pop(pi)\n",
    "    \n",
    "print(f\"size after pruning: {len(neighbor_cnt)}\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a59e0cb",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### calculating tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac1acb3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for pi, neighs in tqdm(neighbor_cnt.items()):\n",
    "    for phrase in neighs.keys():\n",
    "        neighs[phrase] /= most_frequent_pis[phrase]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d69a95",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### calculating using bi-partite method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37077142",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy import sparse, io\n",
    "\n",
    "pi_idx = {}\n",
    "for pi in most_frequent_pis:\n",
    "    pi_idx[pi] = len(pi_idx)\n",
    "\n",
    "#creating bipartite matrix\n",
    "usr_pi = []\n",
    "\n",
    "for bio in bios:\n",
    "    cur_usr_pis = []\n",
    "    for pi in bio:\n",
    "        if pi in most_frequent_pis:\n",
    "            cur_usr_pis.append(pi_idx[pi])\n",
    "    if len(cur_usr_pis) < 2:\n",
    "        continue\n",
    "    usr_pi.append(cur_usr_pis)\n",
    "    \n",
    "\n",
    "print(f\"original users: {len(bios)}\")\n",
    "print(f\"no of users after pruning: {len(usr_pi)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae185fc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "usrs = []\n",
    "pis = []\n",
    "scores = []\n",
    "\n",
    "for uid, pis in enumerate(usr_pi):\n",
    "    for pi in pis:\n",
    "        usrs.append(uid)\n",
    "        pis.append(pi)\n",
    "        scores.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf9be0f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%% time\n",
    "\n",
    "BP_MATRIX_FILENAME = \"./bipartite_pi.mtx\"\n",
    "output_matrix = sparse.coo_matrix((scores, (usrs, pis)))\n",
    "io.mmwrite(BP_MATRIX_FILENAME, output_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72cad62",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!du -hs ./bipartite_pi.mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12192548",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy import io\n",
    "\n",
    "io.mmread(BP_MATRIX_FILENAME, output_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44744b56",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3123d499",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!rm ./bipartite_pi.mtx.gz\n",
    "!gzip ./bipartite_pi.mtx\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6010f65c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../bipartite-pairs/python-scoring/\")\n",
    "import score_data\n",
    "\n",
    "BP_SCORING_OUTPUT = './bipartite_output.csv.gz'\n",
    "score_data.score_only(\n",
    "    BP_MATRIX_FILENAME+\".gz\",\n",
    "    ['weighted_corr_exp'],\n",
    "    BP_SCORING_OUTPUT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2698bdfc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!zcat ./bipartite_output.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94224328",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "BP_SCORING_OUTPUT = './bipartite_output.csv.gz'\n",
    "df = pd.read_csv(BP_SCORING_OUTPUT)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0fdd88",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# recreate the neighboring dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe12e66c",
   "metadata": {},
   "source": [
    "### save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66c7124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pis = []\n",
    "positives = []\n",
    "negatives = []\n",
    "\n",
    "for pi, cntr in tqdm(neighbor_cnt.items()):\n",
    "    cur_neg = [x for x in most_frequent_pis if x not in neighbor_cnt[pi]]\n",
    "    if len(cur_neg) > 20:\n",
    "        cur_neg = list(np.random.choice(cur_neg, size=20, replace=False))\n",
    "    cur_pos = [x[0] for x in neighbor_cnt[pi].most_common(5)]\n",
    "    if len(cur_neg) < 4 or len(neighbor_cnt[pi])<2:\n",
    "        print(f\"PASSING PI: {pi}\")\n",
    "        continue\n",
    "    positives.append(cur_pos)\n",
    "    pis.append(pi)\n",
    "    negatives.append(cur_neg)\n",
    "                 \n",
    "print(f\"saving {len(pis)} pis\")\n",
    "df = pd.DataFrame({'pis': pis, 'positives': positives, 'negatives': negatives})\n",
    "df.to_csv('twitter_pi_with_neighbors_tfidf.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea41545",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l wiki_pi_with_neighbors_standard.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb1fc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head wiki_pi_with_neighbors_standard.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e553a1",
   "metadata": {},
   "source": [
    "## create test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e18435a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "lower_bios = []\n",
    "for bio in bios:\n",
    "    lower_bio = []\n",
    "    for pi in bio:\n",
    "        lower_bio.append(pi.lower())\n",
    "    lower_bios.append(lower_bio)\n",
    "    \n",
    "train, test = train_test_split(bios, test_size=0.2, shuffle=True)\n",
    "print(len(train), len(test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407be37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./data/wiki_test_bios.pkl', 'wb') as f:\n",
    "    pickle.dump(test, f)\n",
    "    \n",
    "with open('./data/wiki_train_bios.pkl', 'wb') as f:\n",
    "    pickle.dump(train, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbf8c10",
   "metadata": {},
   "source": [
    "# Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24388589",
   "metadata": {},
   "source": [
    "## phrase cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5008d8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./data/wiki_train_bios.pkl', 'rb') as f:\n",
    "    bios = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ea45e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a vocabulary of phrases\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter\n",
    "\n",
    "pi_cnt = Counter()\n",
    "for bio in tqdm(bios):\n",
    "    pi_cnt.update(bio)\n",
    "\n",
    "len(pi_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fde7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "neighbor_cnt = {}\n",
    "\n",
    "for bio in tqdm(bios):\n",
    "    for pi in bio:\n",
    "        if pi in pi_cnt:\n",
    "            if pi not in neighbor_cnt:\n",
    "                neighbor_cnt[pi] = Counter()\n",
    "                \n",
    "            rest = [b for b in bio if b!=pi and b in pi_cnt]\n",
    "            neighbor_cnt[pi].update(rest)\n",
    "\n",
    "print(len(neighbor_cnt))            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79ad7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_cnt.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad1f8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_cnt.most_common(len(pi_cnt))[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89587ee3",
   "metadata": {},
   "source": [
    "## cleaning each bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5283dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# phrases of lenght at least l\n",
    "# profiles with at least k phrases\n",
    "# pis that's been repeated at least m times in dataset\n",
    "\n",
    "def clean_pis(all_pis):\n",
    "    result = []\n",
    "    for pis in tqdm(all_pis):\n",
    "        current_pi = set()\n",
    "        for pi in pis:\n",
    "            if len(pi) >= 2 and pi_cnt[pi] >= 1:\n",
    "                current_pi.add(pi)\n",
    "        if len(current_pi) > 1:\n",
    "            result.append(list(current_pi))\n",
    "            \n",
    "    return result\n",
    "            \n",
    "cleaned_bios = clean_pis(bios)\n",
    "print(len(cleaned_bios), len(bios))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8579a27",
   "metadata": {},
   "source": [
    "# Contrastive learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4049e62",
   "metadata": {},
   "source": [
    "## generating positive negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfb8b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.distplot([len(b) for b in bios])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c4ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import numpy as np\n",
    "\n",
    "def pair_in_list(current_pair, l):\n",
    "    for pair in l:\n",
    "        if current_pair[0] in pair and current_pair[1] in pair:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def generate_triplets(bios, k=3):\n",
    "    samples = []\n",
    "    pi_set = list(pi_cnt.keys())\n",
    "    for idx, bio in tqdm(enumerate(bios), total=len(bios)):\n",
    "        iters = min(len(bio)-1, k)\n",
    "        chosen_pis = []\n",
    "        for i in range(iters):\n",
    "            pos1, pos2 = np.random.choice(bio, size=2, replace=False)\n",
    "            while pair_in_list([pos1,pos2], chosen_pis):\n",
    "                pos1, pos2 = np.random.choice(bio, size=2, replace=False)\n",
    "            chosen_pis.append([pos1, pos2])\n",
    "            neg_idx = randint(0, len(pi_set)-1)\n",
    "            while pi_set[neg_idx] in neighbor_cnt[pos1] or pi_set[neg_idx] in neighbor_cnt[pos2]:\n",
    "                neg_idx = randint(0, len(pi_set)-1)\n",
    "            samples.append([pos1, pos2, pi_set[neg_idx]])\n",
    "    return samples\n",
    "\n",
    "triplets = generate_triplets(cleaned_bios, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ef2d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(triplets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d18ff5",
   "metadata": {},
   "source": [
    "## save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b096589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('data/triplets.pkl', 'wb') as f:\n",
    "    pickle.dump(triplets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7a0d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('data/triplets.pkl', 'rb') as f:\n",
    "    triplets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7dbd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(triplets, test_size=0.01, shuffle=True)\n",
    "train_set, valid_set = train_test_split(train_set, test_size=0.01, shuffle=True)\n",
    "\n",
    "print(f\"train size: {len(train_set)}, validation size: {len(valid_set)}, test size: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9209cd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# writing the data into the file\n",
    "with open('data/valid.csv', 'w') as f:   \n",
    "    write = csv.writer(f, delimiter='\\t')\n",
    "    write.writerows(valid_set)\n",
    "    \n",
    "with open('data/train.csv', 'w') as f:   \n",
    "    write = csv.writer(f, delimiter='\\t')\n",
    "    write.writerows(train_set)\n",
    "\n",
    "with open('data/test.pckl', 'wb') as f:   \n",
    "    pickle.dump(test_set, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba7ad2d",
   "metadata": {},
   "source": [
    "## finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf22515a",
   "metadata": {},
   "source": [
    "### building the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72d8c754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "381450it [00:02, 133765.67it/s]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, util\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "with open('data/train.csv', newline='') as f:\n",
    "    train_examples = []\n",
    "    reader = csv.reader(f, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "    for row in tqdm(reader):\n",
    "        train_examples.append(InputExample(texts=[row[0], row[1]], label=1.0))\n",
    "        train_examples.append(InputExample(texts=[row[0], row[2]], label=0.0))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ca3a11",
   "metadata": {},
   "source": [
    "### loading evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f1ae891",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3854it [00:00, 518120.70it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sentence_transformers import evaluation\n",
    "\n",
    "with open('data/valid.csv', newline='') as f:\n",
    "    sent1s = []\n",
    "    sent2s = []\n",
    "    scores = []\n",
    "    i = 0\n",
    "    reader = csv.reader(f, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "    for row in tqdm(reader):\n",
    "        sent1s.append(row[0])\n",
    "        sent1s.append(row[0])\n",
    "        sent2s.append(row[1])\n",
    "        sent2s.append(row[2])\n",
    "        scores.append(1.0)\n",
    "        scores.append(0.0)\n",
    "        i += 1\n",
    "evaluator = evaluation.EmbeddingSimilarityEvaluator(sent1s, sent2s, scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d645e1e0",
   "metadata": {},
   "source": [
    "### creating data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "253e199f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "from torch import nn\n",
    "\n",
    "model_name = 'all-MiniLM-L6-v2'\n",
    "model = SentenceTransformer(model_name)\n",
    "# dense_model = models.Dense(in_features=model.get_sentence_embedding_dimension(), out_features=100, activation_function=nn.Tanh())\n",
    "# model.add_module('3', dense_model)\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=128)\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6804d7",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30365eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/academic/kjoseph/navid/workspace/transformers/src/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a8e41cb7394c0ea50101825e4a10f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8d47df35d54590bb2bf986f70d0214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5961 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_model_path = 'models/miniLM-L6-finetuned-wiki2'\n",
    "\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=5,\n",
    "          evaluation_steps=2500,\n",
    "          warmup_steps=5000,\n",
    "          output_path=output_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67356ab1",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f996d9b",
   "metadata": {},
   "source": [
    "### loading saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99293b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba41ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "\n",
    "model = SentenceTransformer('./models/miniLM-L6-finetuned-wiki/')\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee894bf",
   "metadata": {},
   "source": [
    "### calculating encodings for all phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad34c86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pis = set()\n",
    "\n",
    "for bio in cleaned_bios:\n",
    "    pis.update(bio)\n",
    "\n",
    "pis = list(pis)\n",
    "print(len(pis))\n",
    "\n",
    "embeddings = model.encode(pis, convert_to_tensor=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237ba151",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def most_similar(pi, all_pis, all_pi_embs, model, k=11):\n",
    "    cur_emb = model.encode(pi, convert_to_tensor=True)\n",
    "    cosine_scores = util.cos_sim(cur_emb, all_pi_embs).detach().cpu().numpy()[0]\n",
    "    most_similars = np.argsort(cosine_scores)[-k:]\n",
    "    return [(all_pis[i], cosine_scores[i]) for i in most_similars if pi!=all_pis[i]]\n",
    "\n",
    "most_similar('mima', pis, embeddings, model, k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94edeb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(w1, w2, model=model):\n",
    "    emb1 = model.encode(w1, convert_to_tensor=True)\n",
    "    emb2 = model.encode(w2, convert_to_tensor=True)\n",
    "    return util.cos_sim(emb1, emb2)\n",
    "\n",
    "print(\n",
    "    get_similarity('isfj', 'man'),\n",
    "    get_similarity('isfj', 'woman'),\n",
    "    get_similarity('isfj', 'man', model=model),\n",
    "    get_similarity('isfj', 'woman', model=model),\n",
    ")\n",
    "\n",
    "print(\n",
    "    get_similarity('intj', 'man'),\n",
    "    get_similarity('intj', 'woman'),\n",
    "    get_similarity('intj', 'man', model=model),\n",
    "    get_similarity('intj', 'woman', model=model),\n",
    ")\n",
    "\n",
    "print(\n",
    "    get_similarity('entj', 'man'),\n",
    "    get_similarity('entj', 'woman'),\n",
    "    get_similarity('entj', 'man', model=model),\n",
    "    get_similarity('entj', 'woman', model=model),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1f8c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "mom_emb = base_model.encode('intp', convert_to_tensor=True)\n",
    "dad_emb = base_model.encode('esfj', convert_to_tensor=True)\n",
    "util.cos_sim(mom_emb, dad_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2821f8ae",
   "metadata": {},
   "source": [
    "### loading not tuned model and doing the same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffd31d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "\n",
    "base_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "base_embs = base_model.encode(pis, convert_to_tensor=True)\n",
    "base_cosine_scores = util.cos_sim(base_embs, base_embs).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84054f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "target_word = 'build the wall'\n",
    "df1 = pd.DataFrame(most_similar(target_word, pis, embeddings, model), columns=['identifier', 'similarity'])\n",
    "df1['model'] = 'fine-tuned-sentence-bert'\n",
    "df2 = pd.DataFrame(most_similar(target_word, pis, base_embs, base_model), columns=['identifier', 'similarity'])\n",
    "df2['model'] = 'original-sentence-bert'\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(15,6))\n",
    "\n",
    "ax1.scatter(x=df1['identifier'], y=df1['similarity'])\n",
    "ax1.tick_params(axis='x', rotation=-60)\n",
    "ax1.set_xlabel('phrase')\n",
    "ax1.set_ylabel('similarity')\n",
    "ax1.set_title('fine-tuned-sentence-bert')\n",
    "\n",
    "\n",
    "ax2.scatter(x=df2['identifier'], y=df2['similarity'])\n",
    "ax2.tick_params(axis='x', rotation=-60)\n",
    "ax2.set_xlabel('phrase')\n",
    "ax2.set_ylabel('similarity')\n",
    "ax2.set_title('original-sentence-bert')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad9278e",
   "metadata": {},
   "source": [
    "### analyzing personalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22507a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for personality in ['ESTJ', 'ENTJ', 'ESFJ', 'ENFJ', 'ISTJ', 'ISFJ', 'INTJ', 'INFJ', 'ESTP', 'ESFP', 'ENTP', 'ENFP', 'ISTP', 'ISFP', 'INTP', 'INFP']:\n",
    "    if personality in pis or personality.lower() in pis:\n",
    "        print(f\"{personality}: True\")\n",
    "    else:\n",
    "        print(f\"{personality}: False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1b63b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "personalities = ['ESTJ', 'ENTJ', 'ESFJ', 'ENFJ', 'ISTJ', 'ISFJ', 'INTJ', 'INFJ', 'ESTP', 'ESFP', 'ENTP', 'ENFP', 'ISTP', 'ISFP', 'INTP', 'INFP']\n",
    "personalities = [p.lower() for p in personalities]\n",
    "\n",
    "pers_emb = model.encode(personalities, convert_to_tensor=True)\n",
    "pers_emb_base = base_model.encode(personalities, convert_to_tensor=True)\n",
    "\n",
    "base_cosine_scores = util.cos_sim(pers_emb_base, pers_emb_base).detach().cpu().numpy()\n",
    "cosine_scores = util.cos_sim(pers_emb, pers_emb).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406d3001",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "ax = sns.heatmap(cosine_scores)\n",
    "ax.set_xticklabels(personalities, rotation=90)\n",
    "ax.set_yticklabels(personalities, rotation=0)\n",
    "\n",
    "# plt.xticks(ticks=personalities)\n",
    "# plt.yticks(ticks=personalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1ab792",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "ax = sns.heatmap(base_cosine_scores)\n",
    "ax.set_xticklabels(personalities, rotation=90)\n",
    "ax.set_yticklabels(personalities, rotation=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c00590e",
   "metadata": {},
   "source": [
    "### comparing in gensim vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40dfb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "w2v = api.load(\"glove-wiki-gigaword-50\")\n",
    "w2v.most_similar(\"glass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636e7a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(w2v.key_to_index.keys())\n",
    "\n",
    "vocab_embs = model.encode(vocab, convert_to_tensor=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036f73ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar('vaccine', vocab, vocab_embs, model, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b650b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar('blm', vocab, vocab_embs, model, k=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e679f9e7",
   "metadata": {},
   "source": [
    "# Word2vec embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bee5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('/user/smadani/navid/data/pis2020.pkl', 'rb') as f:\n",
    "    bios = pickle.load(f)\n",
    "    \n",
    "bios[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f51047e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print(len(bios))\n",
    "\n",
    "class Callback(CallbackAny2Vec):\n",
    "    '''Callback to print loss after each epoch.'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.loss_to_be_subed = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        loss_now = loss - self.loss_to_be_subed\n",
    "        self.loss_to_be_subed = loss\n",
    "        print('Loss after epoch {}: {}'.format(self.epoch, loss_now))\n",
    "        self.epoch += 1\n",
    "\n",
    "monitor = Callback()\n",
    "model = Word2Vec(bios, vector_size=256, window=5, min_count=1,\n",
    "                 negative=10, workers=30, epochs=100, callbacks=[monitor],\n",
    "                 compute_loss=True)\n",
    "\n",
    "model.save('./models/w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc4c356",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"./models/w2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65904ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar('he', topn=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befc7b98",
   "metadata": {},
   "source": [
    "# Downstream tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a84e0e",
   "metadata": {},
   "source": [
    "## hold-one-out prediction of PIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43527519",
   "metadata": {},
   "source": [
    "### clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "127e7647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "985429\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/wiki_test_bios.pkl', 'rb') as f:\n",
    "    test_bios = pickle.load(f)\n",
    "\n",
    "with open('data/wiki_train_bios.pkl', 'rb') as f:\n",
    "    train_bios = pickle.load(f)\n",
    "    \n",
    "all_bios = train_bios + test_bios\n",
    "print(len(all_bios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3231d408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/11885247/ipykernel_15087/608534976.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for bio in tqdm(all_bios):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c54166bc4243f09bed9399922a82c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/985429 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "55009"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a vocabulary of phrases\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter\n",
    "\n",
    "pi_cnt = Counter()\n",
    "for bio in tqdm(all_bios):\n",
    "    pi_cnt.update(bio)\n",
    "\n",
    "len(pi_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca3cb98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/11885247/ipykernel_15087/454695413.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for pis in tqdm(all_pis):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae86bbf0fa242a392bfc8be1f831b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/985429 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d475b4afc91488aa24e2db0afff0414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/197086 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# phrases of lenght at least 2\n",
    "# profiles with at least 2 phrases\n",
    "# pis that's been repeated at least 10 times in dataset\n",
    "\n",
    "def clean_pis(all_pis):\n",
    "    result = []\n",
    "    for pis in tqdm(all_pis):\n",
    "        current_pi = set()\n",
    "        for pi in pis:\n",
    "            if len(pi) >= 2 and pi_cnt[pi] >= 1:\n",
    "                current_pi.add(pi)\n",
    "        if len(current_pi) > 1:\n",
    "            result.append(list(current_pi))\n",
    "            \n",
    "    return result\n",
    "            \n",
    "cleaned_all_bios = clean_pis(all_bios)\n",
    "cleaned_test_bios = clean_pis(test_bios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eed8fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['actress', 'bondage model'],\n",
       " ['volleyball player', 'gold medalist'],\n",
       " ['singer', 'guitarist']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_all_bios[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d786fbb9",
   "metadata": {},
   "source": [
    "### create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa5f11d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62250\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_ds = []\n",
    "\n",
    "\n",
    "for bio in cleaned_test_bios:\n",
    "    hold_out_idx = np.random.randint(0, len(bio))\n",
    "    remaining = [x for i, x in enumerate(bio) if i != hold_out_idx]\n",
    "    remaining = ', '.join(remaining)\n",
    "    target = bio[hold_out_idx]\n",
    "    \n",
    "    test_ds.append((remaining, target))\n",
    "\n",
    "print(len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5abb2cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pis = set()\n",
    "for bio in cleaned_all_bios:\n",
    "    for pi in bio:\n",
    "        all_pis.add(pi)\n",
    "\n",
    "all_pis = list(all_pis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fb6b0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46189\n"
     ]
    }
   ],
   "source": [
    "print(len(all_pis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62e3452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "pi_dict = OrderedDict()\n",
    "for p in all_pis:\n",
    "    pi_dict[p] = len(pi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ed23ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46189\n"
     ]
    }
   ],
   "source": [
    "print(len(pi_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "413d6ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62250 62250\n"
     ]
    }
   ],
   "source": [
    "bio_x, bio_y = zip(*test_ds)\n",
    "print(len(bio_y), len(bio_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a246f35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch \n",
    "\n",
    "def get_results_batched(model, tokenizer, str_l, bs=256, average_k_layers=1):\n",
    "    i = 0\n",
    "    result = []\n",
    "    pbar = tqdm(total=len(str_l))\n",
    "    while i < len(str_l):\n",
    "        batch = list(str_l[i:i+bs])\n",
    "        with torch.no_grad():\n",
    "            tokens = tokenizer(batch, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "            res_full = model(**tokens).hidden_states\n",
    "            layers = []\n",
    "\n",
    "            for k in range(-average_k_layers,0):\n",
    "                pooled_val = res_full[k]\n",
    "                # taking cls token embeddings\n",
    "                layers.append(pooled_val[:,0,:])\n",
    "\n",
    "            stacked_layers = torch.stack(layers, dim=1)\n",
    "            #print(stacked_layers.shape)\n",
    "\n",
    "            average_embs = torch.mean(stacked_layers, dim=1)\n",
    "            #print(average_embs.shape)\n",
    "\n",
    "            result.append(average_embs.detach().cpu())\n",
    "            i = i + bs\n",
    "            pbar.update(bs)\n",
    "    return torch.concat(result, dim=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea73d94c",
   "metadata": {},
   "source": [
    "### load original bert and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19d54816",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\n",
      "  0%|          | 0/62250 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 512/62250 [00:00<00:15, 4094.50it/s]\u001b[A\n",
      "  2%|▏         | 1024/62250 [00:00<00:15, 3982.84it/s]\u001b[A\n",
      "  2%|▏         | 1536/62250 [00:00<00:14, 4069.35it/s]\u001b[A\n",
      "  3%|▎         | 2048/62250 [00:00<00:14, 4247.09it/s]\u001b[A\n",
      "  4%|▍         | 2560/62250 [00:00<00:13, 4334.07it/s]\u001b[A\n",
      "  5%|▍         | 3072/62250 [00:00<00:13, 4429.19it/s]\u001b[A\n",
      "  6%|▌         | 3584/62250 [00:00<00:13, 4425.23it/s]\u001b[A\n",
      "  7%|▋         | 4096/62250 [00:00<00:12, 4502.98it/s]\u001b[A\n",
      "  7%|▋         | 4608/62250 [00:01<00:12, 4677.53it/s]\u001b[A\n",
      "  8%|▊         | 5120/62250 [00:01<00:12, 4672.57it/s]\u001b[A\n",
      "  9%|▉         | 5632/62250 [00:01<00:12, 4678.47it/s]\u001b[A\n",
      " 10%|█         | 6400/62250 [00:01<00:11, 4844.87it/s]\u001b[A\n",
      " 11%|█         | 6912/62250 [00:01<00:11, 4788.53it/s]\u001b[A\n",
      " 12%|█▏        | 7424/62250 [00:01<00:11, 4722.73it/s]\u001b[A\n",
      " 13%|█▎        | 8192/62250 [00:01<00:10, 4964.58it/s]\u001b[A\n",
      " 14%|█▍        | 8704/62250 [00:01<00:10, 4971.07it/s]\u001b[A\n",
      " 15%|█▍        | 9216/62250 [00:01<00:10, 4970.97it/s]\u001b[A\n",
      " 16%|█▌        | 9728/62250 [00:02<00:10, 4898.34it/s]\u001b[A\n",
      " 16%|█▋        | 10240/62250 [00:02<00:10, 4921.45it/s]\u001b[A\n",
      " 17%|█▋        | 10752/62250 [00:02<00:10, 4845.06it/s]\u001b[A\n",
      " 18%|█▊        | 11264/62250 [00:02<00:10, 4835.03it/s]\u001b[A\n",
      " 19%|█▉        | 11776/62250 [00:02<00:10, 4827.49it/s]\u001b[A\n",
      " 20%|█▉        | 12288/62250 [00:02<00:10, 4838.86it/s]\u001b[A\n",
      " 21%|██        | 13056/62250 [00:02<00:09, 4990.63it/s]\u001b[A\n",
      " 22%|██▏       | 13824/62250 [00:02<00:09, 4980.04it/s]\u001b[A\n",
      " 23%|██▎       | 14592/62250 [00:03<00:09, 5006.95it/s]\u001b[A\n",
      " 24%|██▍       | 15104/62250 [00:03<00:09, 4892.87it/s]\u001b[A\n",
      " 25%|██▌       | 15872/62250 [00:03<00:09, 5023.00it/s]\u001b[A\n",
      " 26%|██▋       | 16384/62250 [00:03<00:09, 4974.85it/s]\u001b[A\n",
      " 27%|██▋       | 16896/62250 [00:03<00:09, 4964.12it/s]\u001b[A\n",
      " 28%|██▊       | 17408/62250 [00:03<00:09, 4831.37it/s]\u001b[A\n",
      " 29%|██▉       | 17920/62250 [00:03<00:09, 4901.32it/s]\u001b[A\n",
      " 30%|██▉       | 18432/62250 [00:03<00:08, 4949.98it/s]\u001b[A\n",
      " 30%|███       | 18944/62250 [00:03<00:08, 4921.83it/s]\u001b[A\n",
      " 31%|███▏      | 19456/62250 [00:04<00:08, 4904.18it/s]\u001b[A\n",
      " 32%|███▏      | 19968/62250 [00:04<00:08, 4913.72it/s]\u001b[A\n",
      " 33%|███▎      | 20736/62250 [00:04<00:08, 4967.76it/s]\u001b[A\n",
      " 34%|███▍      | 21248/62250 [00:04<00:08, 4852.74it/s]\u001b[A\n",
      " 35%|███▌      | 22016/62250 [00:04<00:08, 4940.57it/s]\u001b[A\n",
      " 37%|███▋      | 22784/62250 [00:04<00:07, 5005.52it/s]\u001b[A\n",
      " 37%|███▋      | 23296/62250 [00:04<00:07, 4973.33it/s]\u001b[A\n",
      " 38%|███▊      | 23808/62250 [00:04<00:08, 4756.71it/s]\u001b[A\n",
      " 39%|███▉      | 24576/62250 [00:05<00:07, 4921.48it/s]\u001b[A\n",
      " 40%|████      | 25088/62250 [00:05<00:07, 4865.16it/s]\u001b[A\n",
      " 41%|████      | 25600/62250 [00:05<00:07, 4928.17it/s]\u001b[A\n",
      " 42%|████▏     | 26368/62250 [00:05<00:07, 5091.36it/s]\u001b[A\n",
      " 43%|████▎     | 26880/62250 [00:05<00:06, 5086.77it/s]\u001b[A\n",
      " 44%|████▍     | 27392/62250 [00:05<00:06, 5039.18it/s]\u001b[A\n",
      " 45%|████▍     | 27904/62250 [00:05<00:06, 5044.13it/s]\u001b[A\n",
      " 46%|████▌     | 28416/62250 [00:05<00:06, 5047.91it/s]\u001b[A\n",
      " 47%|████▋     | 29184/62250 [00:06<00:06, 5147.27it/s]\u001b[A\n",
      " 48%|████▊     | 29952/62250 [00:06<00:06, 4922.31it/s]\u001b[A\n",
      " 49%|████▉     | 30464/62250 [00:06<00:06, 4909.75it/s]\u001b[A\n",
      " 50%|█████     | 31232/62250 [00:06<00:06, 5016.89it/s]\u001b[A\n",
      " 51%|█████     | 31744/62250 [00:06<00:06, 5035.64it/s]\u001b[A\n",
      " 52%|█████▏    | 32512/62250 [00:06<00:05, 5128.25it/s]\u001b[A\n",
      " 53%|█████▎    | 33280/62250 [00:06<00:05, 5191.55it/s]\u001b[A\n",
      " 55%|█████▍    | 34048/62250 [00:06<00:05, 5075.59it/s]\u001b[A\n",
      " 56%|█████▌    | 34560/62250 [00:07<00:05, 5061.34it/s]\u001b[A\n",
      " 56%|█████▋    | 35072/62250 [00:07<00:05, 4998.76it/s]\u001b[A\n",
      " 57%|█████▋    | 35584/62250 [00:07<00:05, 5025.28it/s]\u001b[A\n",
      " 58%|█████▊    | 36096/62250 [00:07<00:05, 4964.84it/s]\u001b[A\n",
      " 59%|█████▉    | 36864/62250 [00:07<00:04, 5136.72it/s]\u001b[A\n",
      " 60%|██████    | 37376/62250 [00:07<00:04, 4980.17it/s]\u001b[A\n",
      " 61%|██████    | 37888/62250 [00:07<00:04, 4940.53it/s]\u001b[A\n",
      " 62%|██████▏   | 38400/62250 [00:07<00:05, 4679.46it/s]\u001b[A\n",
      " 63%|██████▎   | 39168/62250 [00:08<00:04, 4791.79it/s]\u001b[A\n",
      " 64%|██████▍   | 39936/62250 [00:08<00:04, 4916.51it/s]\u001b[A\n",
      " 65%|██████▍   | 40448/62250 [00:08<00:04, 4906.94it/s]\u001b[A\n",
      " 66%|██████▌   | 41216/62250 [00:08<00:04, 4958.47it/s]\u001b[A\n",
      " 67%|██████▋   | 41984/62250 [00:08<00:04, 5023.50it/s]\u001b[A\n",
      " 68%|██████▊   | 42496/62250 [00:08<00:04, 4886.59it/s]\u001b[A\n",
      " 69%|██████▉   | 43008/62250 [00:08<00:03, 4904.66it/s]\u001b[A\n",
      " 70%|███████   | 43776/62250 [00:08<00:03, 5070.60it/s]\u001b[A\n",
      " 72%|███████▏  | 44544/62250 [00:09<00:03, 5053.96it/s]\u001b[A\n",
      " 73%|███████▎  | 45312/62250 [00:09<00:03, 5013.53it/s]\u001b[A\n",
      " 74%|███████▎  | 45824/62250 [00:09<00:03, 4798.46it/s]\u001b[A\n",
      " 74%|███████▍  | 46336/62250 [00:09<00:03, 4788.25it/s]\u001b[A\n",
      " 76%|███████▌  | 47104/62250 [00:09<00:03, 5044.54it/s]\u001b[A\n",
      " 76%|███████▋  | 47616/62250 [00:09<00:02, 5063.05it/s]\u001b[A\n",
      " 78%|███████▊  | 48384/62250 [00:09<00:02, 5061.05it/s]\u001b[A\n",
      " 79%|███████▉  | 49152/62250 [00:10<00:02, 5037.46it/s]\u001b[A\n",
      " 80%|████████  | 49920/62250 [00:10<00:02, 5105.79it/s]\u001b[A\n",
      " 81%|████████  | 50432/62250 [00:10<00:02, 5062.95it/s]\u001b[A\n",
      " 82%|████████▏ | 50944/62250 [00:10<00:02, 5073.40it/s]\u001b[A\n",
      " 83%|████████▎ | 51456/62250 [00:10<00:02, 4605.17it/s]\u001b[A\n",
      " 83%|████████▎ | 51968/62250 [00:10<00:02, 4554.54it/s]\u001b[A\n",
      " 84%|████████▍ | 52480/62250 [00:10<00:02, 4669.54it/s]\u001b[A\n",
      " 86%|████████▌ | 53248/62250 [00:10<00:01, 5003.46it/s]\u001b[A\n",
      " 87%|████████▋ | 54016/62250 [00:11<00:01, 5098.53it/s]\u001b[A\n",
      " 88%|████████▊ | 54784/62250 [00:11<00:01, 5134.10it/s]\u001b[A\n",
      " 89%|████████▉ | 55296/62250 [00:11<00:01, 5069.16it/s]\u001b[A\n",
      " 90%|█████████ | 56064/62250 [00:11<00:01, 5102.50it/s]\u001b[A\n",
      " 91%|█████████ | 56576/62250 [00:11<00:01, 5050.48it/s]\u001b[A\n",
      " 92%|█████████▏| 57344/62250 [00:11<00:00, 5085.99it/s]\u001b[A\n",
      " 93%|█████████▎| 57856/62250 [00:11<00:00, 4913.85it/s]\u001b[A\n",
      " 94%|█████████▍| 58368/62250 [00:11<00:00, 4661.65it/s]\u001b[A\n",
      " 95%|█████████▍| 59136/62250 [00:12<00:00, 4875.62it/s]\u001b[A\n",
      " 96%|█████████▌| 59648/62250 [00:12<00:00, 4791.02it/s]\u001b[A\n",
      " 97%|█████████▋| 60160/62250 [00:12<00:00, 4869.07it/s]\u001b[A\n",
      " 98%|█████████▊| 60928/62250 [00:12<00:00, 4973.17it/s]\u001b[A\n",
      " 99%|█████████▉| 61696/62250 [00:12<00:00, 5036.53it/s]\u001b[A\n",
      "62464it [00:12, 4920.44it/s]                           \u001b[A\n",
      "\n",
      "  0%|          | 0/46189 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 768/46189 [00:00<00:06, 6530.79it/s]\u001b[A\n",
      "  3%|▎         | 1536/46189 [00:00<00:06, 6618.42it/s]\u001b[A\n",
      "  5%|▍         | 2304/46189 [00:00<00:06, 6644.00it/s]\u001b[A\n",
      "  7%|▋         | 3072/46189 [00:00<00:06, 6597.94it/s]\u001b[A\n",
      "  8%|▊         | 3840/46189 [00:00<00:06, 6670.90it/s]\u001b[A\n",
      " 10%|▉         | 4608/46189 [00:00<00:06, 6671.30it/s]\u001b[A\n",
      " 12%|█▏        | 5376/46189 [00:00<00:06, 6675.16it/s]\u001b[A\n",
      " 13%|█▎        | 6144/46189 [00:00<00:06, 6638.51it/s]\u001b[A\n",
      " 15%|█▍        | 6912/46189 [00:01<00:06, 6514.44it/s]\u001b[A\n",
      " 17%|█▋        | 7680/46189 [00:01<00:05, 6454.45it/s]\u001b[A\n",
      " 18%|█▊        | 8448/46189 [00:01<00:05, 6358.42it/s]\u001b[A\n",
      " 20%|█▉        | 9216/46189 [00:01<00:05, 6378.07it/s]\u001b[A\n",
      " 22%|██▏       | 9984/46189 [00:01<00:05, 6317.65it/s]\u001b[A\n",
      " 23%|██▎       | 10752/46189 [00:01<00:05, 6324.18it/s]\u001b[A\n",
      " 25%|██▍       | 11520/46189 [00:01<00:05, 6241.48it/s]\u001b[A\n",
      " 27%|██▋       | 12288/46189 [00:01<00:05, 6172.16it/s]\u001b[A\n",
      " 28%|██▊       | 13056/46189 [00:02<00:05, 6239.01it/s]\u001b[A\n",
      " 30%|██▉       | 13824/46189 [00:02<00:05, 6215.92it/s]\u001b[A\n",
      " 32%|███▏      | 14592/46189 [00:02<00:05, 6078.80it/s]\u001b[A\n",
      " 33%|███▎      | 15360/46189 [00:02<00:05, 6148.69it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 16128/46189 [00:02<00:04, 6149.22it/s]\u001b[A\n",
      " 37%|███▋      | 16896/46189 [00:02<00:04, 6117.35it/s]\u001b[A\n",
      " 38%|███▊      | 17664/46189 [00:02<00:04, 6066.24it/s]\u001b[A\n",
      " 40%|███▉      | 18432/46189 [00:02<00:04, 6049.76it/s]\u001b[A\n",
      " 42%|████▏     | 19200/46189 [00:03<00:04, 6062.07it/s]\u001b[A\n",
      " 43%|████▎     | 19968/46189 [00:03<00:04, 6047.83it/s]\u001b[A\n",
      " 45%|████▍     | 20736/46189 [00:03<00:04, 6118.20it/s]\u001b[A\n",
      " 47%|████▋     | 21504/46189 [00:03<00:04, 6091.20it/s]\u001b[A\n",
      " 48%|████▊     | 22272/46189 [00:03<00:03, 6028.85it/s]\u001b[A\n",
      " 50%|████▉     | 23040/46189 [00:03<00:03, 6087.49it/s]\u001b[A\n",
      " 52%|█████▏    | 23808/46189 [00:03<00:03, 6040.97it/s]\u001b[A\n",
      " 53%|█████▎    | 24576/46189 [00:03<00:03, 6045.94it/s]\u001b[A\n",
      " 55%|█████▍    | 25344/46189 [00:04<00:03, 5988.44it/s]\u001b[A\n",
      " 57%|█████▋    | 26112/46189 [00:04<00:03, 5994.74it/s]\u001b[A\n",
      " 58%|█████▊    | 26880/46189 [00:04<00:03, 6008.05it/s]\u001b[A\n",
      " 60%|█████▉    | 27648/46189 [00:04<00:03, 5770.18it/s]\u001b[A\n",
      " 62%|██████▏   | 28416/46189 [00:04<00:03, 5824.28it/s]\u001b[A\n",
      " 63%|██████▎   | 29184/46189 [00:04<00:02, 5815.70it/s]\u001b[A\n",
      " 65%|██████▍   | 29952/46189 [00:04<00:02, 5868.56it/s]\u001b[A\n",
      " 67%|██████▋   | 30720/46189 [00:04<00:02, 5824.99it/s]\u001b[A\n",
      " 68%|██████▊   | 31488/46189 [00:05<00:02, 5508.53it/s]\u001b[A\n",
      " 70%|██████▉   | 32256/46189 [00:05<00:02, 5579.77it/s]\u001b[A\n",
      " 71%|███████▏  | 33024/46189 [00:05<00:02, 5665.90it/s]\u001b[A\n",
      " 73%|███████▎  | 33792/46189 [00:05<00:02, 5664.18it/s]\u001b[A\n",
      " 75%|███████▍  | 34560/46189 [00:05<00:02, 5502.45it/s]\u001b[A\n",
      " 76%|███████▋  | 35328/46189 [00:05<00:01, 5628.84it/s]\u001b[A\n",
      " 78%|███████▊  | 36096/46189 [00:05<00:01, 5684.88it/s]\u001b[A\n",
      " 80%|███████▉  | 36864/46189 [00:06<00:01, 5695.28it/s]\u001b[A\n",
      " 81%|████████▏ | 37632/46189 [00:06<00:01, 5773.15it/s]\u001b[A\n",
      " 83%|████████▎ | 38400/46189 [00:06<00:01, 5776.12it/s]\u001b[A\n",
      " 85%|████████▍ | 39168/46189 [00:06<00:01, 5870.18it/s]\u001b[A\n",
      " 86%|████████▋ | 39936/46189 [00:06<00:01, 5927.67it/s]\u001b[A\n",
      " 88%|████████▊ | 40704/46189 [00:06<00:00, 5949.47it/s]\u001b[A\n",
      " 90%|████████▉ | 41472/46189 [00:06<00:00, 5831.17it/s]\u001b[A\n",
      " 91%|█████████▏| 42240/46189 [00:07<00:00, 5828.12it/s]\u001b[A\n",
      " 93%|█████████▎| 43008/46189 [00:07<00:00, 5862.64it/s]\u001b[A\n",
      " 95%|█████████▍| 43776/46189 [00:07<00:00, 5880.20it/s]\u001b[A\n",
      " 96%|█████████▋| 44544/46189 [00:07<00:00, 5813.46it/s]\u001b[A\n",
      " 98%|█████████▊| 45312/46189 [00:07<00:00, 5850.84it/s]\u001b[A\n",
      "46336it [00:07, 6020.30it/s]                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([62250, 768]) torch.Size([46189, 768])\n",
      "CPU times: user 20.3 s, sys: 1.92 s, total: 22.2 s\n",
      "Wall time: 31.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "import torch\n",
    "\n",
    "device = 'cuda:1'\n",
    "\n",
    "config = BertConfig.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\", config=config)\n",
    "bert_model = bert_model.to(device)\n",
    "bert_model.eval()\n",
    "\n",
    "\n",
    "bert_emb_x = get_results_batched(bert_model, bert_tokenizer, bio_x, average_k_layers=3)\n",
    "bert_emb_all = get_results_batched(bert_model, bert_tokenizer, all_pis, average_k_layers=3)\n",
    "\n",
    "print(bert_emb_x.shape, bert_emb_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b73357",
   "metadata": {},
   "source": [
    "### calculate rank score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a9d9d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/academic/kjoseph/navid/anaconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/snapshot_download.py:6: FutureWarning: snapshot_download.py has been made private and will no longer be available from version 0.11. Please use `from huggingface_hub import snapshot_download` to import the only public function in this module. Other members of the file may be changed without a deprecation notice.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([62250])\n",
      "CPU times: user 9min 17s, sys: 33.2 s, total: 9min 50s\n",
      "Wall time: 4min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, models, util\n",
    "\n",
    "device = 'cpu'\n",
    "cosine_scores = util.cos_sim(bert_emb_x.to(device), bert_emb_all.to(device))\n",
    "ranks = torch.argsort(torch.argsort(cosine_scores, dim=1, descending=True), dim=1)\n",
    "target_idxs = torch.tensor([pi_dict[y] for y in bio_y], dtype=torch.int64)\n",
    "print(target_idxs.shape)\n",
    "target_ranks = torch.gather(ranks, 1, target_idxs.unsqueeze(1).reshape(-1,1)).type(torch.FloatTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b15955ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2072, tensor(14324.7344))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([r for r in target_ranks.squeeze().tolist() if r < 100]), torch.mean(target_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b10b27",
   "metadata": {},
   "source": [
    "### load original sentence bert and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7333db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/62250 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 2048/62250 [00:00<00:03, 18965.64it/s]\u001b[A\n",
      "  7%|▋         | 4096/62250 [00:00<00:03, 18974.41it/s]\u001b[A\n",
      " 11%|█         | 6656/62250 [00:00<00:02, 21869.84it/s]\u001b[A\n",
      " 16%|█▌        | 9728/62250 [00:00<00:02, 24447.43it/s]\u001b[A\n",
      " 20%|██        | 12544/62250 [00:00<00:01, 25709.87it/s]\u001b[A\n",
      " 25%|██▌       | 15616/62250 [00:00<00:01, 26951.42it/s]\u001b[A\n",
      " 30%|███       | 18688/62250 [00:00<00:01, 27497.28it/s]\u001b[A\n",
      " 35%|███▍      | 21504/62250 [00:00<00:01, 27238.28it/s]\u001b[A\n",
      " 39%|███▉      | 24576/62250 [00:00<00:01, 27515.59it/s]\u001b[A\n",
      " 44%|████▍     | 27648/62250 [00:01<00:01, 27983.68it/s]\u001b[A\n",
      " 49%|████▉     | 30464/62250 [00:01<00:01, 27811.36it/s]\u001b[A\n",
      " 54%|█████▍    | 33536/62250 [00:01<00:01, 28409.32it/s]\u001b[A\n",
      " 59%|█████▉    | 36608/62250 [00:01<00:00, 28282.45it/s]\u001b[A\n",
      " 64%|██████▎   | 39680/62250 [00:01<00:00, 27983.13it/s]\u001b[A\n",
      " 68%|██████▊   | 42496/62250 [00:01<00:00, 27957.07it/s]\u001b[A\n",
      " 73%|███████▎  | 45568/62250 [00:01<00:00, 28177.46it/s]\u001b[A\n",
      " 78%|███████▊  | 48640/62250 [00:01<00:00, 27999.48it/s]\u001b[A\n",
      " 83%|████████▎ | 51456/62250 [00:01<00:00, 27268.63it/s]\u001b[A\n",
      " 88%|████████▊ | 54528/62250 [00:02<00:00, 27833.35it/s]\u001b[A\n",
      " 93%|█████████▎| 57600/62250 [00:02<00:00, 27671.98it/s]\u001b[A\n",
      "62464it [00:02, 26909.46it/s]                           \u001b[A\n",
      "\n",
      "  0%|          | 0/46189 [00:00<?, ?it/s]\u001b[A\n",
      "  8%|▊         | 3584/46189 [00:00<00:01, 34260.99it/s]\u001b[A\n",
      " 16%|█▌        | 7168/46189 [00:00<00:01, 34292.30it/s]\u001b[A\n",
      " 23%|██▎       | 10752/46189 [00:00<00:02, 13371.50it/s]\u001b[A\n",
      " 31%|███       | 14336/46189 [00:00<00:01, 17626.16it/s]\u001b[A\n",
      " 39%|███▉      | 17920/46189 [00:00<00:01, 21416.74it/s]\u001b[A\n",
      " 47%|████▋     | 21504/46189 [00:00<00:01, 24648.42it/s]\u001b[A\n",
      " 54%|█████▍    | 25088/46189 [00:01<00:00, 27259.80it/s]\u001b[A\n",
      " 62%|██████▏   | 28672/46189 [00:01<00:00, 29241.71it/s]\u001b[A\n",
      " 70%|██████▉   | 32256/46189 [00:01<00:00, 30496.75it/s]\u001b[A\n",
      " 78%|███████▊  | 35840/46189 [00:01<00:00, 31543.52it/s]\u001b[A\n",
      " 85%|████████▌ | 39424/46189 [00:01<00:00, 32464.72it/s]\u001b[A\n",
      "46336it [00:01, 27086.96it/s]                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.63 s, sys: 3.18 s, total: 11.8 s\n",
      "Wall time: 5.07 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, models, util\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "device = 'cuda:1'\n",
    "# orig_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# orig_model = orig_model.to(device)\n",
    "\n",
    "#orig_emb_x = orig_model.encode(bio_x, `convert_to_tensor=True)\n",
    "#orig_emb_all = orig_model.encode(all_pis, convert_to_tensor=True)\n",
    "\n",
    "sbert_tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "sbert_model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2', output_hidden_states=True)\n",
    "sbert_model = sbert_model.to(device)\n",
    "sbert_model.eval()\n",
    "\n",
    "sbert_emb_x = get_results_batched(sbert_model, sbert_tokenizer, bio_x, bs=256, average_k_layers=3)\n",
    "sbert_emb_all = get_results_batched(sbert_model, sbert_tokenizer, all_pis, bs=256, average_k_layers=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905bd51b",
   "metadata": {},
   "source": [
    "### calculate rank score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f3e7a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 1s, sys: 27.5 s, total: 9min 28s\n",
      "Wall time: 4min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "\n",
    "device='cpu'\n",
    "cosine_scores = util.cos_sim(sbert_emb_x, sbert_emb_all)\n",
    "ranks = torch.argsort(torch.argsort(cosine_scores.to(device), dim=1, descending=True), dim=1)\n",
    "target_idxs = torch.tensor([pi_dict[y] for y in bio_y], dtype=torch.int64)\n",
    "target_ranks = torch.gather(ranks, 1, target_idxs.unsqueeze(1).reshape(-1,1)).type(torch.FloatTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f77c5a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4406, tensor(7061.2729))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([r for r in target_ranks.squeeze().tolist() if r < 100]), torch.mean(target_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e4dc40",
   "metadata": {},
   "source": [
    "### load finetuned sentence bert and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d967a030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 467 ms, sys: 34.4 ms, total: 502 ms\n",
      "Wall time: 232 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 384)\n",
       "    (token_type_embeddings): Embedding(2, 384)\n",
       "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, models, util\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "fint_tokenizer = AutoTokenizer.from_pretrained('./models/miniLM-L6-finetuned-wiki/')\n",
    "fint_model = AutoModel.from_pretrained('./models/miniLM-L6-finetuned-wiki/', output_hidden_states=True)\n",
    "fint_model = fint_model.to(device)\n",
    "fint_model.eval()\n",
    "\n",
    "fint_emb_x = get_results_batched(fint_model, fint_tokenizer, bio_x, bs=256, average_k_layers=3)\n",
    "fint_emb_all = get_results_batched(fint_model, fint_tokenizer, all_pis, bs=256, average_k_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c54747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09e57a29",
   "metadata": {},
   "source": [
    "### calculate rank score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9caa214c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 59s, sys: 27.4 s, total: 9min 26s\n",
      "Wall time: 4min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "\n",
    "device='cpu'\n",
    "cosine_scores_fint = util.cos_sim(fint_emb_x, fint_emb_all)\n",
    "ranks_fint = torch.argsort(torch.argsort(cosine_scores_fint.to(device), dim=1, descending=True), dim=1)\n",
    "target_idxs = torch.tensor([pi_dict[y] for y in bio_y], dtype=torch.int64)\n",
    "target_ranks_fint = torch.gather(ranks_fint, 1, target_idxs.unsqueeze(1).reshape(-1,1)).type(torch.FloatTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81e13632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17930, tensor(8684.3525))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([r for r in target_ranks_fint.reshape(1,-1).squeeze().tolist() if r < 100]), torch.mean(target_ranks_fint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe137609",
   "metadata": {},
   "source": [
    "# build survey questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8af9de",
   "metadata": {},
   "source": [
    "## neighborhood score + negative sampling choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d522613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "df = pd.read_csv('twitter_pi_with_neighbors_tfidf.csv')\n",
    "print(df.head())\n",
    "df.positives = df.positives.apply(literal_eval)\n",
    "df.negatives = df.negatives.apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd980929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from random import randint\n",
    "\n",
    "pis = df['pis']\n",
    "positives = df['positives']\n",
    "negatives = df['negatives']\n",
    "\n",
    "sample_cnt = 500\n",
    "questions = []\n",
    "targets = []\n",
    "other_choices = []\n",
    "\n",
    "sample_idices = np.random.randint(0, len(df), size=sample_cnt)\n",
    "\n",
    "for qid in sample_idices:\n",
    "    q = pis[qid]\n",
    "    cur_pos = positives[qid]\n",
    "    cur_neg = negatives[qid]\n",
    "    target = cur_pos[randint(0,len(cur_pos)-1)]\n",
    "    targets.append(target)\n",
    "    questions.append(q)\n",
    "    other_choices.append(np.random.choice(cur_neg, size=3, replace=False))\n",
    "    \n",
    "res = pd.DataFrame({'question_pi': questions, 'ans_pi': targets, 'other_choices': other_choices})\n",
    "res.to_csv('surrvey_tfidf_twitter.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86922b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head surrvey_tfidf_twitter.csv -n 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e799829b",
   "metadata": {},
   "source": [
    "## model based question generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3166fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models, util\n",
    "\n",
    "fint_model = SentenceTransformer('./models/miniLM-L6-finetuned/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ac0a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from random import randint\n",
    "\n",
    "\n",
    "all_pis = df['pis']\n",
    "sims = df['similars']\n",
    "sample_cnt = 500\n",
    "\n",
    "questions = []\n",
    "targets = []\n",
    "other_choices = []\n",
    "\n",
    "i = 0\n",
    "while i < sample_cnt:\n",
    "    idx = randint(0, len(all_pis)-1)\n",
    "    questions.append(all_pis[idx])\n",
    "    i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ea973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fint_emb_x = fint_model.encode(questions, convert_to_tensor=True)\n",
    "fint_emb_all = fint_model.encode(all_pis, convert_to_tensor=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b25cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "targets = []\n",
    "other_choices = []\n",
    "\n",
    "for x in tqdm(fint_emb_x):\n",
    "    cosine_scores = util.cos_sim(x, fint_emb_all).detach().cpu().numpy()[0]\n",
    "    argsort = np.argsort(cosine_scores)\n",
    "    best_k = argsort[-6:-1]\n",
    "    worst_k = argsort[:len(argsort)//2]\n",
    "    \n",
    "    target_idx = np.random.choice(best_k)\n",
    "    targets.append(all_pis[target_idx])\n",
    "    \n",
    "    other_idxs = np.random.choice(worst_k, size=3, replace=False)\n",
    "    other_choices.append([all_pis[x] for x in other_idxs])\n",
    "    \n",
    "    \n",
    "res = pd.DataFrame({'question_pi': questions, 'ans_pi': targets, 'other_choices': other_choices})\n",
    "res.to_csv('modelbased-selection.csv', index=False, header=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf38c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head modelbased-selection.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae77b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.075px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
